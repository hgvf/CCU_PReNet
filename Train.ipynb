{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpwvtYwbpV-Z","scrolled":true,"executionInfo":{"status":"ok","timestamp":1609683491590,"user_tz":-480,"elapsed":2137,"user":{"displayName":"湯冠維","photoUrl":"","userId":"18305826138266983570"}},"outputId":"20eb7b44-4ee1-4c2d-9248-e4896eaed2ce"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","import os\n","os.chdir('gdrive/My Drive/Colab Notebooks')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KfPE4pj3sXbC","executionInfo":{"status":"ok","timestamp":1609683492202,"user_tz":-480,"elapsed":2741,"user":{"displayName":"湯冠維","photoUrl":"","userId":"18305826138266983570"}}},"source":["%run Network.ipynb\n","%run Datasets.ipynb\n","%run SSIM.ipynb"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_PRjyXJypV-f","executionInfo":{"status":"ok","timestamp":1609683493337,"user_tz":-480,"elapsed":3871,"user":{"displayName":"湯冠維","photoUrl":"","userId":"18305826138266983570"}}},"source":["import os\n","from os import listdir\n","import argparse\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import MultiStepLR\n","import matplotlib.pyplot as plt\n","import torchvision.utils as utils\n","from skimage.measure.simple_metrics import compare_psnr\n","\n","#from utils import *"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VXq5kGBUyQgs","executionInfo":{"status":"ok","timestamp":1609683493338,"user_tz":-480,"elapsed":3867,"user":{"displayName":"湯冠維","photoUrl":"","userId":"18305826138266983570"}},"outputId":"76ceef61-565f-49da-8a0b-a8b52f750d02"},"source":["# Image 的前置處理\n","\n","trns = transforms.Compose([transforms.Scale((150,150))])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:280: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n","  \"please use transforms.Resize instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"aB8qFS66j7b2","executionInfo":{"status":"ok","timestamp":1609683493339,"user_tz":-480,"elapsed":3862,"user":{"displayName":"湯冠維","photoUrl":"","userId":"18305826138266983570"}}},"source":["def batch_PSNR(img, imclean, data_range):\n","    Img = img.data.cpu().numpy().astype(np.float32)\n","    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n","    PSNR = 0\n","    for i in range(Img.shape[0]):\n","        PSNR += compare_psnr(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n","    return (PSNR/Img.shape[0])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBMSgGynpV-j","executionInfo":{"status":"ok","timestamp":1609683493340,"user_tz":-480,"elapsed":3858,"user":{"displayName":"湯冠維","photoUrl":"","userId":"18305826138266983570"}},"outputId":"493dc302-3a4d-49ef-9004-e725d408fe20"},"source":["# 讀取資料集\n","print(\"Loading datasets...\")\n","            \n","# 運用 dataloader 操作 datasets\n","datasets_train = PReNet_train_datasets(transform=trns)\n","loader_train = DataLoader(dataset=datasets_train, batch_size=8, shuffle=True)\n","\n","# 建立 model\n","model = PReNet(6)\n","\n","# Loss function\n","criterion = SSIM()\n","\n","# Optimizer\n","optimizer = optim.SGD(model.parameters(), lr=1e-3)\n","scheduler = MultiStepLR(optimizer, milestones=[30,50,80], gamma=0.2)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Loading datasets...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"gsBGE4ICpV-n","executionInfo":{"status":"error","timestamp":1609683714636,"user_tz":-480,"elapsed":225148,"user":{"displayName":"湯冠維","photoUrl":"","userId":"18305826138266983570"}},"outputId":"d77231fe-9ea4-453f-b584-3afacda3e4c0"},"source":["# 開始訓練 model\n","\n","step = 0\n","for epoch in range(10):\n","    print('epoch = ', epoch)\n","    # 進度\n","    #scheduler.step(epoch)\n","    for param_group in optimizer.param_groups:\n","        print('learning rate %f' %param_group[\"lr\"])\n","    \n","    # 訓練\n","    for i, (input_train, target_train) in enumerate(loader_train, 0):\n","        #o = input_train.permute(0,3,1,2)\n","        #o = o.reshape(1, 3, 100, 200)\n","        #o = o.squeeze(0)\n","        #print(o.shape)\n","        #new_img = transforms.ToPILImage()(o).convert('RGB')\n","        #trns = transforms.Compose([transforms.Scale((640,480))])\n","        #new_img = trns(new_img)\n","        #display(new_img)    \n","      \n","        print(\"img_size = \", input_train.shape)\n","        model.train()\n","        model.zero_grad()\n","        optimizer.zero_grad()\n","        input_train, target_train = Variable(input_train), Variable(target_train)\n","\n","        # training's output\n","        out_train, _ = model(input_train.permute(0, 3, 1, 2))\n","\n","        target_train = target_train.permute(0, 3, 1, 2)\n","        pixel_metric = criterion(target_train, out_train)\n","        print('pixel_metric = ', pixel_metric)\n","        loss = -pixel_metric\n","        \n","        loss.backward()\n","        optimizer.step()\n","        \n","        # 訓練曲線\n","        model.eval()\n","        out_train, _ = model(input_train.permute(0, 3, 1, 2))\n","        out_train = torch.clamp(out_train, 0., 1.)\n","        psnr_train = batch_PSNR(out_train, target_train, 1.)\n","        print(\"[epoch %d][%d/%d] loss: %.4f, pixel_metric: %.4f, PSNR: %.4f\" %\n","                (epoch+1, i+1, len(loader_train), loss.item(), pixel_metric.item(), psnr_train))\n","        \n","        step += 1\n","\n","\n","        # 輸出影像\n","        model.eval()\n","        out_train, _ = model(input_train.permute(0, 3, 1, 2))\n","        out_train = torch.clamp(out_train, 0., 1.)\n","\n","        #o = out_train.reshape(1, 3, 100, 200)\n","        #o = x.squeeze(0)\n","        \n","        #new_img = transforms.ToPILImage()(o).convert('RGB')\n","\n","        #trns = transforms.Compose([transforms.Scale((640,480))])\n","        #new_img = trns(new_img)\n","        #display(new_img) "],"execution_count":7,"outputs":[{"output_type":"stream","text":["epoch =  0\n","learning rate 0.001000\n","img_size =  torch.Size([8, 150, 150, 3])\n","iteration:  0\n","iteration:  1\n","iteration:  2\n","iteration:  3\n","iteration:  4\n","iteration:  5\n","pixel_metric =  tensor(1.9444e-06, grad_fn=<MeanBackward0>)\n","iteration:  0\n","iteration:  1\n","iteration:  2\n","iteration:  3\n","iteration:  4\n","iteration:  5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: DEPRECATED: skimage.measure.compare_psnr has been moved to skimage.metrics.peak_signal_noise_ratio. It will be removed from skimage.measure in version 0.18.\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["[epoch 1][1/10] loss: -0.0000, pixel_metric: 0.0000, PSNR: -41.2848\n","iteration:  0\n","iteration:  1\n","iteration:  2\n","iteration:  3\n","iteration:  4\n","iteration:  5\n","img_size =  torch.Size([8, 150, 150, 3])\n","iteration:  0\n","iteration:  1\n","iteration:  2\n","iteration:  3\n","iteration:  4\n","iteration:  5\n","pixel_metric =  tensor(2.1031e-06, grad_fn=<MeanBackward0>)\n","iteration:  0\n","iteration:  1\n","iteration:  2\n","iteration:  3\n","iteration:  4\n","iteration:  5\n","[epoch 1][2/10] loss: -0.0000, pixel_metric: 0.0000, PSNR: -41.1816\n","iteration:  0\n","iteration:  1\n","iteration:  2\n","iteration:  3\n","iteration:  4\n","iteration:  5\n","img_size =  torch.Size([8, 150, 150, 3])\n","iteration:  0\n","iteration:  1\n","iteration:  2\n","iteration:  3\n","iteration:  4\n","iteration:  5\n","pixel_metric =  tensor(1.8675e-06, grad_fn=<MeanBackward0>)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-0295271e015a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mpixel_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"l-q7Z1q3pV-q","executionInfo":{"status":"aborted","timestamp":1609683714633,"user_tz":-480,"elapsed":225137,"user":{"displayName":"湯冠維","photoUrl":"","userId":"18305826138266983570"}}},"source":["'''\n","from IPython.display import display\n","\n","out_train = out_train.reshape(1, 3, 100, 200)\n","out_train = out_train.squeeze(0)\n","new_img = transforms.ToPILImage()(out_train).convert('RGB')\n","\n","trns1 = transforms.Compose([transforms.Resize((640,480))])\n","\n","#new_img = trns1(new_img)\n","display(new_img)\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ouPI0_LTPGc2","executionInfo":{"status":"aborted","timestamp":1609683714634,"user_tz":-480,"elapsed":225133,"user":{"displayName":"湯冠維","photoUrl":"","userId":"18305826138266983570"}}},"source":["print(img1.size())\n","\n","img1 = np.array(img1)\n","img2 = np.array(img2)\n","img1 = torch.Tensor(img1)\n","img2 = torch.Tensor(img2)\n","\n","img3 = img1*img2\n","print(img3.size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d9tEnqUWPOBL","executionInfo":{"status":"aborted","timestamp":1609683714635,"user_tz":-480,"elapsed":225130,"user":{"displayName":"湯冠維","photoUrl":"","userId":"18305826138266983570"}}},"source":[""],"execution_count":null,"outputs":[]}]}